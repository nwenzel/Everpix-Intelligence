{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nwenzel/Everpix-Intelligence/blob/master/sentiment_battle.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tKoHvBP1mEIx",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "%pip install langchain langchain_community langchain_core langchain_openai langchain-google-genai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install colab-xterm #https://pypi.org/project/colab-xterm/\n",
        "%load_ext colabxterm"
      ],
      "metadata": {
        "collapsed": true,
        "id": "3LLpyoLdZVOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# curl -fsSL https://ollama.com/install.sh | sh"
      ],
      "metadata": {
        "id": "79dx4jmLZe5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%xterm"
      ],
      "metadata": {
        "collapsed": true,
        "id": "DRhKud4hZXFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "openai = userdata.get(\"OPENAI_API_KEY\")\n",
        "google = userdata.get(\"GOOGLE_API_KEY\")\n",
        "tracing = userdata.get(\"LANGCHAIN_API_KEY\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "tDanpuB06e9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VUMOS7QhiWpr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai\n",
        "os.environ[\"GOOGLE_API_KEY\"] = google\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = tracing\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"office_hours_4\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vvJGwzN9idS0"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_community.llms.ollama import Ollama\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "got_mail_example = \"This film shouldn't work at all. It doesn't have much of a story and the whole dial up internet thing is incredibly dated. However Hanks and Ryan sell it beautifully.\"\n",
        "\n",
        "model_one = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", max_retries=1)\n",
        "model_two = Ollama(model=\"phi3:mini\")\n",
        "model_three = ChatOpenAI(model=\"gpt-4o\")\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(\n",
        "    \"\"\"Analyze the overall sentiment of the following movie review:\n",
        "\n",
        "    REVIEW: {review}\n",
        "\n",
        "    Only return a sentiment of 'positive' or 'negative'. Do not include any other text. You must respond, and respond in a single word.\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "runnable_one = prompt | model_one | output_parser\n",
        "runnable_two = prompt | model_two | output_parser\n",
        "runnable_three = prompt | model_three | output_parser\n",
        "\n",
        "parallel = RunnableParallel(\n",
        "    { \"first_review\": runnable_one,\n",
        "    \"second_review\": runnable_two,\n",
        "    \"review\": RunnablePassthrough(),\n",
        "    }\n",
        ")\n",
        "\n",
        "def analyze(results):\n",
        "    print(\"analyzing results...\")\n",
        "    if results[\"first_review\"].lower().strip() == results[\"second_review\"].lower().strip:\n",
        "        return results[\"first_review\"].lower().strip()\n",
        "    else:\n",
        "        print(\"running tie-breaker\")\n",
        "        return runnable_three.invoke({ \"review\": results[\"review\"] }).lower().strip()\n",
        "\n",
        "analyze(parallel.invoke({ \"review\": got_mail_example }))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Mj1zY_1ihBx"
      },
      "outputs": [],
      "source": []
    }
  ]
}